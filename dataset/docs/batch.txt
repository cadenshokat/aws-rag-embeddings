AWS Batch

User Guide

What is AWS Batch?
AWS Batch helps you to run batch computing workloads on the AWS Cloud. Batch computing
is a common way for developers, scientists, and engineers to access large amounts of compute
resources. AWS Batch removes the undiﬀerentiated heavy lifting of conﬁguring and managing the
required infrastructure, similar to traditional batch computing software. This service can eﬃciently
provision resources in response to jobs submitted in order to eliminate capacity constraints, reduce
compute costs, and deliver results quickly.
As a fully managed service, AWS Batch helps you to run batch computing workloads of any scale.
AWS Batch automatically provisions compute resources and optimizes the workload distribution
based on the quantity and scale of the workloads. With AWS Batch, there's no need to install or
manage batch computing software, so you can focus your time on analyzing results and solving
problems.

1

AWS Batch

User Guide

AWS Batch provides all of the necessary functionality to run high-scale, compute-intensive
workloads on top of AWS managed container orchestration services, Amazon ECS and Amazon EKS.
AWS Batch is able to scale compute capacity on Amazon EC2 instances and Fargate resources.
AWS Batch provides a fully managed service for batch workloads, and delivers the operational
capabilities to optimize these types of workloads for throughput, speed, resource eﬃciency, and
cost.
AWS Batch also enables SageMaker Training job queuing, allowing data scientists and ML engineers
to submit Training jobs with priorities to conﬁgurable queues. This capability ensures that ML
workloads run automatically as soon as resources become available, eliminating the need for
manual coordination and improving resource utilization.
For machine learning workloads, AWS Batch provides queuing capabilities for SageMaker Training
jobs. You can conﬁgure queues with speciﬁc policies to optimize cost, performance, and resource
allocation for your ML Training workloads.

This provides a shared responsibility model where administrators set up the infrastructure and
permissions, while data scientists can focus on submitting and monitoring their ML training
workloads. Jobs are automatically queued and executed based on conﬁgured priorities and
resource availability.

2

AWS Batch

User Guide

Are you a ﬁrst-time AWS Batch user?
If you are a ﬁrst-time user of AWS Batch, we recommend that you begin by reading the following
sections:
• Components of AWS Batch
• Create IAM account and administrative user
• Setting up AWS Batch
• Getting started with AWS Batch tutorials
• Getting started with AWS Batch on SageMaker AI

Related services
AWS Batch is a fully managed batch computing service that plans, schedules, and runs your
containerized batch ML, simulation, and analytics workloads across the full range of AWS compute
oﬀerings, such as Amazon ECS, Amazon EKS, AWS Fargate, and Spot or On-Demand Instances. For
more information about each managed compute service, see:
• Amazon EC2 User Guide
• AWS Fargate Developer Guide
• Amazon EKS User Guide
• Amazon SageMaker AI Developer Guide

Accessing AWS Batch
You can access AWS Batch using the following:
AWS Batch console
The web interface where you create and manage resources.
AWS Command Line Interface
Interact with AWS services using commands in your command line shell. The AWS Command
Line Interface is supported on Windows, macOS, and Linux. For more information about the
AWS CLI, see AWS Command Line Interface User Guide. You can ﬁnd the AWS Batch commands
in the AWS CLI Command Reference.
Are you a ﬁrst-time AWS Batch user?

3

AWS Batch

User Guide

AWS SDKs
If you prefer to build applications using language-speciﬁc APIs instead of submitting a request
over HTTP or HTTPS, use the libraries, sample code, tutorials, and other resources provided by
AWS. These libraries provide basic functions that automate tasks, such as cryptographically
signing your requests, retrying requests, and handling error responses. These functions make it
more eﬃcient for you to get started. For more information, see Tools to Build on AWS.

Components of AWS Batch
AWS Batch simpliﬁes running batch jobs across multiple Availability Zones within a Region. You
can create AWS Batch compute environments within a new or existing VPC. After a compute
environment is up and associated with a job queue, you can deﬁne job deﬁnitions that specify
which Docker container images to run your jobs. Container images are stored in and pulled from
container registries, which may exist within or outside of your AWS infrastructure.

Compute environment
A compute environment is a set of managed or unmanaged compute resources that are used to
run jobs. With managed compute environments, you can specify desired compute type (Fargate
or EC2) at several levels of detail. You can set up compute environments that use a particular type
of EC2 instance, a particular model such as c5.2xlarge or m5.10xlarge. Or, you can choose
only to specify that you want to use the newest instance types. You can also specify the minimum,
desired, and maximum number of vCPUs for the environment, along with the amount that you're
Components of AWS Batch

4

AWS Batch

User Guide

willing to pay for a Spot Instance as a percentage of the On-Demand Instance price and a target
set of VPC subnets. AWS Batch eﬃciently launches, manages, and terminates compute types as
needed. You can also manage your own compute environments. As such, you're responsible for
setting up and scaling the instances in an Amazon ECS cluster that AWS Batch creates for you. For
more information, see Compute environments for AWS Batch.

Job queues
When you submit an AWS Batch job, you submit it to a particular job queue, where the
job resides until it's scheduled onto a compute environment. You associate one or more
compute environments with a job queue. You can also assign priority values for these compute
environments and even across job queues themselves. For example, you can have a high priority
queue that you submit time-sensitive jobs to, and a low priority queue for jobs that can run
anytime when compute resources are cheaper. For more information, see Job queues.

Job deﬁnitions
A job deﬁnition speciﬁes how jobs are to be run. You can think of a job deﬁnition as a blueprint for
the resources in your job. You can supply your job with an IAM role to provide access to other AWS
resources. You also specify both memory and CPU requirements. The job deﬁnition can also control
container properties, environment variables, and mount points for persistent storage. Many of
the speciﬁcations in a job deﬁnition can be overridden by specifying new values when submitting
individual Jobs. For more information, see Job deﬁnitions

Jobs
A unit of work (such as a shell script, a Linux executable, or a Docker container image) that you
submit to AWS Batch. It has a name, and runs as a containerized application on AWS Fargate or
Amazon EC2 resources in your compute environment, using parameters that you specify in a job
deﬁnition. Jobs can reference other jobs by name or by ID, and can be dependent on the successful
completion of other jobs or the availability of resources you specify. For more information, see
Jobs.

Scheduling policy
You can use scheduling policies to conﬁgure how compute resources in a job queue are allocated
between users or workloads. Using fair-share scheduling policies, you can assign diﬀerent share
identiﬁers to workloads or users. The AWS Batch job scheduler defaults to a ﬁrst-in, ﬁrst-out (FIFO)
strategy. For more information, see Fair-share scheduling policies.
Job queues

5

AWS Batch

User Guide

Consumable resources
A consumable resource is a resource that is needed to run your jobs, such as a 3rd party license
token, database access bandwidth, the need to throttle calls to a third-party API, and so on.
You specify the consumable resources which are needed for a job to run, and Batch takes these
resource dependencies into account when it schedules a job. You can reduce the under-utilization
of compute resources by allocating only the jobs that have all the required resources available. For
more information, see Resource-aware scheduling .

Service Environment
A Service Environment deﬁne how AWS Batch integrates with SageMaker for job execution. Service
Environments enable AWS Batch to submit and manage jobs on SageMaker while providing the
queuing, scheduling, and priority management capabilities of AWS Batch. Service Environments
deﬁne capacity limits for speciﬁc service types such as SageMaker Training jobs. The capacity limits
control the maximum resources that can be used by service jobs in the environment. For more
information, see Service environments for AWS Batch.

Service job
A service job is a unit of work that you submit to AWS Batch to run on a service environment.
Service jobs leverage AWS Batch's queuing and scheduling capabilities while delegating actual
execution to the external service. For example, SageMaker Training jobs submitted as service
jobs are queued and prioritized by AWS Batch, but the SageMaker Training job execution occurs
within SageMaker AI infrastructure. This integration enables data scientists and ML engineers
to beneﬁt from AWS Batch's automated workload management, and priority queuing, for their
SageMaker AI Training workloads. Service jobs can reference other jobs by name or ID and support
job dependencies. For more information, see Service jobs in AWS Batch.

Consumable resources

6

AWS Batch

User Guide

Setting up AWS Batch
If you've already signed up for Amazon Web Services (AWS) and are using Amazon Elastic Compute
Cloud (Amazon EC2) or Amazon Elastic Container Service (Amazon ECS), you can soon use AWS
Batch. The setup process for these services is similar. This is because AWS Batch uses Amazon ECS
container instances in its compute environments. To use the AWS CLI with AWS Batch, you must
use a version of the AWS CLI that supports the latest AWS Batch features. If you don't see support
for an AWS Batch feature in the AWS CLI, upgrade to the latest version. For more information, see
http://aws.amazon.com/cli/.
Note
Because AWS Batch uses components of Amazon EC2, you use the Amazon EC2 console for
many of these steps.

Complete the following tasks to get set up for AWS Batch.
Topics
• Create IAM account and administrative user
• Create IAM roles for your compute environments and container instances
• Create a key pair for your instances
• Create a VPC
• Create a security group
• Install the AWS CLI

Create IAM account and administrative user
To get started, you need to create an AWS account and a single user that is typically granted
administrative rights. To accomplish this, complete the following tutorials:

Sign up for an AWS account
If you do not have an AWS account, complete the following steps to create one.
Create IAM account and administrative user

7

AWS Batch

User Guide

To sign up for an AWS account
1.

Open https://portal.aws.amazon.com/billing/signup.

2.

Follow the online instructions.
Part of the sign-up procedure involves receiving a phone call or text message and entering a
veriﬁcation code on the phone keypad.
When you sign up for an AWS account, an AWS account root user is created. The root user
has access to all AWS services and resources in the account. As a security best practice, assign
administrative access to a user, and use only the root user to perform tasks that require root
user access.

AWS sends you a conﬁrmation email after the sign-up process is complete. At any time, you can
view your current account activity and manage your account by going to https://aws.amazon.com/
and choosing My Account.

Create a user with administrative access
After you sign up for an AWS account, secure your AWS account root user, enable AWS IAM Identity
Center, and create an administrative user so that you don't use the root user for everyday tasks.
Secure your AWS account root user
1.

Sign in to the AWS Management Console as the account owner by choosing Root user and
entering your AWS account email address. On the next page, enter your password.
For help signing in by using root user, see Signing in as the root user in the AWS Sign-In User
Guide.

2.

Turn on multi-factor authentication (MFA) for your root user.
For instructions, see Enable a virtual MFA device for your AWS account root user (console) in
the IAM User Guide.

Create a user with administrative access
1.

Enable IAM Identity Center.

Create a user with administrative access

8

AWS Batch

User Guide

For instructions, see Enabling AWS IAM Identity Center in the AWS IAM Identity Center User
Guide.
2.

In IAM Identity Center, grant administrative access to a user.
For a tutorial about using the IAM Identity Center directory as your identity source, see
Conﬁgure user access with the default IAM Identity Center directory in the AWS IAM Identity
Center User Guide.

Sign in as the user with administrative access
•

To sign in with your IAM Identity Center user, use the sign-in URL that was sent to your email
address when you created the IAM Identity Center user.
For help signing in using an IAM Identity Center user, see Signing in to the AWS access portal in
the AWS Sign-In User Guide.

Assign access to additional users
1.

In IAM Identity Center, create a permission set that follows the best practice of applying leastprivilege permissions.
For instructions, see Create a permission set in the AWS IAM Identity Center User Guide.

2.

Assign users to a group, and then assign single sign-on access to the group.
For instructions, see Add groups in the AWS IAM Identity Center User Guide.

Create IAM roles for your compute environments and container
instances
Your AWS Batch compute environments and container instances require AWS account credentials
to make calls to other AWS APIs on your behalf. Create an AWS Identity and Access Management
role that provides these credentials to your compute environments and container instances, then
associate that role with your compute environments.

Create IAM roles

9

AWS Batch

User Guide

Note
To verify that your AWS account has the required permissions, see Initial IAM service set up
for your account.
The AWS Batch compute environment and container instance roles are automatically
created for you in the console ﬁrst-run experience. So, if you intend to use the AWS
Batch console, you can move ahead to the next section. If you plan to use the AWS CLI
instead, complete the procedures in Using service-linked roles for AWS Batch, Amazon ECS
instance role, and Tutorial: Create the IAM execution role before creating your ﬁrst compute
environment.

Create a key pair for your instances
AWS uses public-key cryptography to secure the login information for your instance. A Linux
instance, such as an AWS Batch compute environment container instance, has no password to use
for SSH access. You use a key pair to log in to your instance securely. You specify the name of the
key pair when you create your compute environment, then provide the private key when you log in
using SSH.
If you didn't create a key pair already, you can create one using the Amazon EC2 console. Note that,
if you plan to launch instances in multiple AWS Regions, create a key pair in each Region. For more
information about Regions, see Regions and Availability Zones in the Amazon EC2 User Guide.
To create a key pair
1.

Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.

2.

From the navigation bar, select an AWS Region for the key pair. You can select any Region
that's available to you, regardless of your location: however, key pairs are speciﬁc to a Region.
For example, if you plan to launch an instance in the US West (Oregon) Region, create a key
pair for the instance in the same Region.

3.

In the navigation pane, choose Key Pairs, Create Key Pair.

4.

In the Create Key Pair dialog box, for Key pair name, enter a name for the new key pair , and
choose Create. Choose a name that you can remember, such as your user name, followed by key-pair, plus the Region name. For example, me-key-pair-uswest2.

Create a key pair

10

AWS Batch

5.

User Guide

The private key ﬁle is automatically downloaded by your browser. The base ﬁle name is the
name that you speciﬁed as the name of your key pair, and the ﬁle name extension is .pem.
Save the private key ﬁle in a safe place.
Important
This is the only chance for you to save the private key ﬁle. You need to provide the
name of your key pair when you launch an instance and the corresponding private key
each time that you connect to the instance.

6.

If you use an SSH client on a Mac or Linux computer to connect to your Linux instance, use the
following command to set the permissions of your private key ﬁle. That way, only you can read
it.
$ chmod 400 your_user_name-key-pair-region_name.pem

For more information, see Amazon EC2 Key Pairs in the Amazon EC2 User Guide.
To connect to your instance using your key pair
To connect to your Linux instance from a computer running Mac or Linux, specify the .pem ﬁle
to your SSH client with the -i option and the path to your private key. To connect to your Linux
instance from a computer running Windows, use either MindTerm or PuTTY. If you plan to use
PuTTY, install it and use the following procedure to convert the .pem ﬁle to a .ppk ﬁle.
(Optional) To prepare to connect to a Linux instance from Windows using PuTTY
1.

Download and install PuTTY from http://www.chiark.greenend.org.uk/~sgtatham/putty/. Be
sure to install the entire suite.

2.

Start PuTTYgen (for example, from the Start menu, choose All Programs, PuTTY, and
PuTTYgen).

3.

Under Type of key to generate, choose RSA. If you're using an earlier version of PuTTYgen,
choose SSH-2 RSA.

Create a key pair

11

AWS Batch

4.

User Guide

Choose Load. By default, PuTTYgen displays only ﬁles with the extension .ppk. To locate your
.pem ﬁle, choose the option to display ﬁles of all types.

5.

Select the private key ﬁle that you created in the previous procedure and choose Open.
Choose OK to dismiss the conﬁrmation dialog box.

6.

Choose Save private key. PuTTYgen displays a warning about saving the key without a
passphrase. Choose Yes.

7.

Specify the same name for the key that you used for the key pair. PuTTY automatically adds
the .ppk ﬁle extension.

Create a VPC
With Amazon Virtual Private Cloud (Amazon VPC), you can launch AWS resources into a virtual
network that you've deﬁned. We strongly recommend that you launch your container instances in a
VPC.
If you have a default VPC, you also can skip this section and move to the next task Create a security
group. To determine whether you have a default VPC, see Supported Platforms in the Amazon EC2
Console in the Amazon EC2 User Guide
For information about how to create an Amazon VPC, see Create a VPC only in the Amazon VPC
User Guide. Refer to the following table to determine what options to select.
Option

Value

Resources to create

VPC only

Name

Optionally provide a name for
your VPC.

IPv4 CIDR block

IPv4 CIDR manual input
The CIDR block size must
have a size between /16
and /28.

Create a VPC

12

AWS Batch

User Guide

Option

Value

IPv6 CIDR block

No IPv6 CIDR block

Tenancy

Default

For more information about Amazon VPC, see What is Amazon VPC? in the Amazon VPC User Guide.

Create a security group
Security groups act as a ﬁrewall for associated compute environment container instances,
controlling both inbound and outbound traﬃc at the container instance level. A security group can
be used only in the VPC for which it is created.
You can add rules to a security group that enable you to connect to your container instance from
your IP address using SSH. You can also add rules that allow inbound and outbound HTTP and
HTTPS access from anywhere. Add any rules to open ports that are required by your tasks.
Note that if you plan to launch container instances in multiple Regions, you need to create a
security group in each Region. For more information, see Regions and Availability Zones in the
Amazon EC2 User Guide.
Note
You need the public IP address of your local computer, which you can get using a service.
For example, we provide the following service: http://checkip.amazonaws.com/ or https://
checkip.amazonaws.com/. To locate another service that provides your IP address, use the
search phrase "what is my IP address." If you're connecting through an Internet service
provider (ISP) or from behind a ﬁrewall without a static IP address, ﬁnd out the range of IP
addresses that are used by client computers.

To create a security group using the console
1.

Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.

2.

In the navigation pane, choose Security Groups.

3.

Choose Create security group.

Create a security group

13

AWS Batch

4.

User Guide

Enter a name and description for the security group. You cannot change the name and
description of a security group after it is created.

5.

From VPC, choose the VPC.

6.

(Optional) By default, new security groups start with only an outbound rule that allows all
traﬃc to leave the resource. You must add rules to enable any inbound traﬃc or to restrict the
outbound traﬃc.
AWS Batch container instances don't require any inbound ports to be open. However, you
might want to add an SSH rule. That way, you can log into the container instance and examine
the containers in jobs with Docker commands. If you want your container instance to host a job
that runs a web server, you can also add rules for HTTP. Complete the following steps to add
these optional security group rules.
On the Inbound tab, create the following rules and choose Create:
• Choose Add Rule. For Type, choose HTTP. For Source, choose Anywhere (0.0.0.0/0).
• Choose Add Rule. For Type, choose SSH. For Source, choose Custom IP, and specify the
public IP address of your computer or network in Classless Inter-Domain Routing (CIDR)
notation. If your company allocates addresses from a range, specify the entire range, such as
203.0.113.0/24. To specify an individual IP address in CIDR notation, choose My IP. This
adds the routing preﬁx /32 to the public IP address.

Note
For security reasons, we don't recommend that you allow SSH access from all IP
addresses (0.0.0.0/0) to your instance but only for testing purposes and only for a
short time.
7.

You can add tags now, or you can add them later. To add a tag, choose Add new tag and enter
the tag key and value.

8.

Choose Create security group.

To create a security group using the command line, see create-security-group (AWS CLI)
For more information about security groups, see Work with security groups.

Create a security group

14

AWS Batch

User Guide

Install the AWS CLI
To use the AWS CLI with AWS Batch, install the latest AWS CLI version. For information about
installing the AWS CLI or upgrading it to the latest version, see Installing the AWS Command Line
Interface in the AWS Command Line Interface User Guide.

Install the AWS CLI

15

AWS Batch

User Guide

Getting started with AWS Batch tutorials
You can use the AWS Batch ﬁrst-run wizard to get started quickly with AWS Batch. After you
complete the Prerequisites, you can use the ﬁrst-run wizard to create a compute environment, a job
deﬁnition, and a job queue.
You can also submit a sample "Hello World" job using the AWS Batch ﬁrst-run wizard to test your
conﬁguration. If you already have a Docker image that you want to launch in AWS Batch, you can
use that image to create a job deﬁnition.
Afterward, you can use the AWS Batch ﬁrst-run wizard to create a compute environment, job
queue, and submit a sample Hello World job.

Getting started with Amazon EC2 orchestration using the
Wizard
Amazon Elastic Compute Cloud (Amazon EC2) provides scalable computing capacity in the AWS
Cloud. Using Amazon EC2 eliminates your need to invest in hardware up front, so you can develop
and deploy applications faster.
You can use Amazon EC2 to launch as many or as few virtual servers as you need, conﬁgure
security and networking, and manage storage. Amazon EC2 enables you to scale up or down to
handle changes in requirements or spikes in popularity, reducing your need to forecast traﬃc.

Overview
This tutorial demonstrates how to setup AWS Batch with the Wizard to conﬁgure Amazon EC2 and
run Hello World.
Intended Audience
This tutorial is designed for system administrators and developers responsible for setting up,
testing, and deploying AWS Batch.
Features Used
This tutorial shows you how to use the AWS Batch console wizard to:
• Create and conﬁgure an Amazon EC2 compute environment
• Create a job queue.
Getting started with Amazon EC2 using the Wizard

16

AWS Batch

User Guide

• Create a job deﬁnition
• Create and submit a job to run
• View the output of the job in CloudWatch
Time Required
It should take about 10–15 minutes to complete this tutorial.
Regional Restrictions
There are no country or regional restrictions associated with using this solution.
Resource Usage Costs
There's no charge for creating an AWS account. However, by implementing this solution, you
might incur some or all of the costs that are listed in the following table.
Description

Cost (US dollars)

Amazon EC2 instance

You pay for each Amazon EC2 instance that
is created. For more information about
pricing, see Amazon EC2 Pricing.

Prerequisites
Before you begin:
• Create an AWS account if you don't have one.
• Create the ecsInstanceRole Instance role.

Step 1: Create a compute environment
Important
To get started as simply and quickly as possible, this tutorial includes steps with default
settings. Before creating for production use, we recommend that you familiarize yourself
with all settings and deploy with the settings that meet your requirements.

To create a compute environment for an Amazon EC2 orchestration, do the following:
Prerequisites

17

AWS Batch

User Guide

1.

Open the AWS Batch console ﬁrst-run wizard.

2.

For Conﬁgure job and orchestration type, choose Amazon Elastic Compute Cloud(Amazon
EC2).

3.

Choose Next.

4.

In the Compute environment conﬁguration section for Name, specify a unique name for
your compute environment. The name can be up to 128 characters in length. It can contain
uppercase and lowercase letters, numbers, hyphens (-), and underscores (_).

5.

For Instance role, choose an existing instance role that has the required IAM permissions
attached. This instance role allows the Amazon ECS container instances in your compute
environment to make calls to the required AWS API operations. For more information, see
Amazon ECS instance role.
The default name of the Instance role is ecsInstanceRole.

6.

For Instance conﬁguration you can leave the default settings.

7.

For Network conﬁguration use your default VPC for the AWS Region.

8.

Choose Next.

Step 2: Create a job queue
A job queue stores your submitted jobs until the AWS Batch Scheduler runs the job on a resource in
your compute environment. For more information, see Job queues
To create a job queue for an Amazon EC2 orchestration, do the following:
1.

For Job queue conﬁguration for Name, specify a unique name for your job queue. The name
can be up to 128 characters in length. It can contain uppercase and lowercase letters, numbers,
hyphens (-), and underscores (_).

2.

For all other conﬁguration options you can leave the default value.

3.

Choose Next.

Step 3: Create a job deﬁnition
AWS Batch job deﬁnitions specify how jobs are to be run. Even though each job must reference a
job deﬁnition, many of the parameters that are speciﬁed in the job deﬁnition can be overridden at
runtime.
Step 2: Create a job queue

18

AWS Batch

User Guide

To create the job deﬁnition:
1.

For Create a job deﬁnition
a.

for Name, specify a unique name for your job queue. The name can be up to 128
characters in length. It can contain uppercase and lowercase letters, numbers, hyphens (-),
and underscores (_).

b.

For Command - optional you can change hello world to a custom message or leave it
as is.

2.

For all other conﬁguration options you can leave the default value.

3.

Choose Next.

Step 4: Create a job
To create a job, do the following:
1.

In the Job conﬁguration section for Name, specify a unique name for the job. The name can
be up to 128 characters in length. It can contain uppercase and lowercase letters, numbers,
hyphens (-), and underscores (_).

2.

For all other conﬁguration options you can leave the default value.

3.

Choose Next.

Step 5: Review and create
On the Review and create page, review the conﬁguration steps. If you need to make changes,
choose Edit. When you're ﬁnished, choose Create resources.
1.

For Review and create choose Create resources.

2.

A window opens as AWS Batch starts to allocate your resources. Once complete choose Go to
dashboard. On the dashboard you should see all of your allocated resources and that the job is
in the Runnable state. Your job is scheduled to run and should complete in 2–3 minuets.

Step 6: View the Job's output
To view the Job's output, do the following:
Step 4: Create a job

19

AWS Batch

User Guide

1.

In the navigation pane choose Jobs.

2.

In the Job queue drop down choose the Job queue you created for the tutorial.

3.

The Jobs table lists all of your Jobs and what their current status is. Once the Job's Status is
Succeeded choose the Name of the Job to view the Job's details.

4.

In the Details pane choose Log stream name. The CloudWatch console for the Job will open
and there should be one event with the Message of hello world or your custom message.

Step 7: Clean up your tutorial resources
You are charged for the Amazon EC2 instance while it is enabled. You can delete the instance to
stop incurring charges.
To delete the resources you created, do the following:
1.

In the navigation pane choose Job queue.

2.

In the Job queue table choose the Job queue you created for the tutorial.

3.

Choose Disable. Once the Job queue State is Disabled you can choose Delete.

4.

Once the Job queue is deleted, in the navigation pane choose Compute environments.

5.

Choose the compute environment you created for this tutorial and then choose Disable. It may
take 1–2 minuets for the compute environment to complete being disabled.

6.

Once the compute environment’s State is Disabled, choose Delete. It may take 1–2 minuets for
the compute environment to be deleted.

Additional resources
After you complete the tutorial, you might want to explore the following topics::
• Explore the AWS Batch core components. For more information, see Components of AWS Batch.
• Learn more about the diﬀerent Compute Environments available in AWS Batch.
• Learn more about Job queues and their diﬀerent scheduling options.
• Learn more about Job deﬁnitions and the diﬀerent conﬁguration options.
• Learn more about the diﬀerent types of Jobs.

Step 7: Clean up your tutorial resources

20

