[
  "AWS Lambda Developer Guide What is AWS Lambda? You can use AWS Lambda to run code without provisioning or managing servers. Lambda runs your code on a high-availability compute infrastructure and manages all the computing resources, including server and operating system maintenance, capacity provisioning, automatic scaling, and logging. You organize your code into Lambda functions. The Lambda service runs your function only when needed and scales automatically. For pricing information, see AWS Lambda Pricing for details. When using Lambda, you are responsible only for your code. Lambda manages the compute ﬂeet that oﬀers a balance of memory, CPU, network, and other resources to run your code. Because Lambda manages these resources, you cannot log in to compute instances or customize the operating system on provided runtimes. When to use Lambda Lambda is an ideal compute service for application scenarios that need to scale up rapidly, and scale down to zero when not in demand. For example, you can use Lambda for: • Stream processing: Use Lambda and Amazon Kinesis to process real-time streaming data for application activity tracking, transaction order processing, clickstream analysis, data cleansing, log ﬁltering, indexing, social media analysis, Internet of Things (IoT) device data telemetry, and metering. • Web applications: Combine Lambda with other AWS services to build powerful web applications that automatically scale up and down and run in a highly available conﬁguration across multiple data centers. To build web applications with AWS services, developers can use infrastructure as code (IaC) and orchestration tools such as AWS CloudFormation, AWS Cloud Development Kit (AWS CDK), AWS Serverless Application Model, or coordinate complex workﬂows using AWS Step Functions. • Mobile backends: Build backends using Lambda and Amazon API Gateway to authenticate and process API requests. Use AWS Amplify to easily integrate with your iOS, Android, Web, and React",
  "API requests. Use AWS Amplify to easily integrate with your iOS, Android, Web, and React Native frontends. • IoT backends: Build serverless backends using Lambda to handle web, mobile, IoT, and thirdparty API requests. • File processing: Use Amazon Simple Storage Service (Amazon S3) to trigger Lambda data processing in real time after an upload. When to use Lambda 1 AWS Lambda Developer Guide • Database Operations and Integration: Use Lambda to process database interactions both reactively and proactively, from handling queue messages for Amazon RDS operations like user registrations and order submissions, to responding to DynamoDB changes for audit logging, data replication, and automated workﬂows. • Scheduled and Periodic Tasks: Use Lambda with EventBridge rules to execute time-based operations such as database maintenance, data archiving, report generation, and other scheduled business processes using cron-like expressions. How Lambda works Because Lambda is a serverless, event-driven compute service, it uses a diﬀerent programming paradigm than traditional web applications. The following model illustrates how Lambda fundamentally works: 1. You write and organize your code in Lambda functions, which are the basic building blocks you use to create a Lambda application. 2. You control security and access through Lambda permissions, using execution roles to manage what AWS services your functions can interact with and what resource policies can interact with your code. 3. Event sources and AWS services trigger your Lambda functions, passing event data in JSON format, which your functions process (this includes event source mappings). 4. Lambda runs your code with language-speciﬁc runtimes (like Node.js and Python) in execution environments that package your runtime, layers, and extensions. Tip To learn how to build serverless solutions, check out the Serverless Developer Guide. Key features Conﬁgure, control, and deploy secure applications: • Environment variables modify application behavior without new code deployments. • Versions",
  "deploy secure applications: • Environment variables modify application behavior without new code deployments. • Versions safely test new features while maintaining stable production environments. How Lambda works 2 AWS Lambda Developer Guide • Lambda layers optimize code reuse and maintenance by sharing common components across multiple functions. • Code signing enforce security compliance by ensuring only approved code reaches production systems. Scale and perform reliably: • Concurrency and scaling controls precisely manage application responsiveness and resource utilization during traﬃc spikes. • Lambda SnapStart signiﬁcantly reduce cold start times. Lambda SnapStart can provide as low as sub-second startup performance, typically with no changes to your function code. • Response streaming optimize function performance by delivering large payloads incrementally for real-time processing. • Container images package functions with complex dependencies using container workﬂows. Connect and integrate seamlessly: • VPC networks secure sensitive resources and internal services. • File system integration that shares persistent data and manage stateful operations across function invocations. • Function URLs create public-facing APIs and endpoints without additional services. • Lambda extensions augment functions with monitoring, security, and operational tools. Related information • For information on how Lambda works, see How Lambda works. • To start using Lambda, see Create your ﬁrst Lambda function. • For a list of example applications, see Getting started with example applications and patterns. How Lambda works Lambda functions are the basic building blocks you use to build Lambda applications. To write functions, it's essential to understand the core concepts and components that make up the Lambda Related information 3 AWS Lambda Developer Guide programming model. This section will guide you through the fundamental elements you need to know to start building serverless applications with Lambda. • Lambda functions and function handlers - A Lambda function is a small block of code that runs",
  "and function handlers - A Lambda function is a small block of code that runs in response to events. functions are the basic building blocks you use to build applications. Function handlers are the entry point for event objects that your Lambda function code processes. • Lambda execution environment and runtimes - Lambda execution environments manage the resources required to run your function. Run times are the language-speciﬁc environments your functions run in. • Events and triggers - how other AWS services invoke your functions in response to speciﬁc events. • Lambda permissions and roles - how you control who can access your functions and what other AWS services your functions can interact with. Tip If you want to start by understanding serverless development more generally, see Understanding the diﬀerence between traditional and serverless development in the AWS Serverless Developer Guide. Lambda functions and function handlers In Lambda, functions are the fundamental building blocks you use to create applications. A Lambda function is a piece of code that runs in response to events, such as a user clicking a button on a website or a ﬁle being uploaded to an Amazon Simple Storage Service (Amazon S3) bucket. You can think of a function as a kind of self-contained program with the following properties. A Lambda function handler is the method in your function code that processes events. When a function runs in response to an event, Lambda runs the function handler. Data about the event that caused the function to run is passed directly to the handler. While the code in a Lambda function can contain more than one method or function, Lambda functions can only have one handler. To create a Lambda function, you bundle your function code and its dependencies in a deployment package. Lambda supports two types",
  "bundle your function code and its dependencies in a deployment package. Lambda supports two types of deployment package, .zip ﬁle archives and container images. Lambda functions and function handlers 4 AWS Lambda Developer Guide • A function has one speciﬁc job or purpose • They run only when needed in response to speciﬁc events • They automatically stop running when ﬁnished Lambda execution environment and runtimes Lambda functions run inside a secure, isolated execution environment which Lambda manages for you. This execution environment manages the processes and resources that are needed to run your function. When a function is ﬁrst invoked, Lambda creates a new execution environment for the function to run in. After the function has ﬁnished running, Lambda doesn't stop the execution environment right away; if the function is invoked again, Lambda can re-use the existing execution environment. The Lambda execution environment also contains a runtime, a language-speciﬁc environment that relays event information and responses between Lambda and your function. Lambda provides a number of managed runtimes for the most popular programming languages, or you can create your own. For managed runtimes, Lambda automatically applies security updates and patches to functions using the runtime. Events and triggers You can also invoke a Lambda function directly by using the Lambda console, AWS CLI, or one of the AWS Software Development Kits (SDKs). It's more usual in a production application for your function to be invoked by another AWS service in response to a particular event. For example, you might want a function to run whenever an item is added to an Amazon DynamoDB table. To make your function respond to events, you set up a trigger. A trigger connects your function to an event source, and your function can have multiple triggers. When an event occurs, Lambda receives event",
  "source, and your function can have multiple triggers. When an event occurs, Lambda receives event data as a JSON document and converts it into an object that your code can process. You might deﬁne the following JSON format for your event and the Lambda runtime converts this JSON to an object before passing it to your function's handler. Example custom Lambda event { \"Location\": \"SEA\", \"WeatherData\":{ Lambda execution environment and runtimes 5 AWS Lambda Developer Guide \"TemperaturesF\":{ \"MinTempF\": 22, \"MaxTempF\": 78 }, \"PressuresHPa\":{ \"MinPressureHPa\": 1015, \"MaxPressureHPa\": 1027 } } } Stream and queue services like Amazon Kinesis or Amazon SQS, Lambda use an event source mapping instead of a standard trigger. Event source mappings poll the source for new data, batch records together, and then invoke your function with the batched events. For more information, see How event source mappings diﬀer from direct triggers. To understand how a trigger works, start by completing the Use an Amazon S3 trigger tutorial, or for a general overview of using triggers and instructions on creating a trigger using the Lambda console, see Integrating other services. Lambda permissions and roles For Lambda, there are two main types of permissions that you need to conﬁgure: • Permissions that your function needs to access other AWS services • Permissions that other users and AWS services need to access your function The following sections describe both of these permission types and discuss best practices for applying least-privilege permissions. Permissions for functions to access other AWS resources Lambda functions often need to access other AWS resources and perform actions on them. For example, a function might read items from a DynamoDB table, store an object in an S3 bucket, or write to an Amazon SQS queue. To give functions the permissions they need to perform these actions, you",
  "Amazon SQS queue. To give functions the permissions they need to perform these actions, you use an execution role. A Lambda execution role is a special kind of AWS Identity and Access Management (IAM) role, an identity you create in your account that has speciﬁc permissions associated with it deﬁned in a policy. Lambda permissions and roles 6 AWS Lambda Developer Guide Every Lambda function must have an execution role, and a single role can be used by more than one function. When a function is invoked, Lambda assumes the function's execution role and is granted permission to take the actions deﬁned in the role's policy. When you create a function in the Lambda console, Lambda automatically creates an execution role for your function. The role's policy gives your function basic permissions to write log outputs to Amazon CloudWatch Logs. To give your function permission to perform actions on other AWS resources, you need to edit the role to add the extra permissions. The easiest way to add permissions is to use an AWS managed policy. Managed policies are created and administered by AWS and provide permissions for many common use cases. For example, if your function performs CRUD operations on a DynamoDB table, you can add the AmazonDynamoDBFullAccess policy to your role. Permissions for other users and resources to access your function To grant other AWS service permission to access your Lambda function, you use a resourcebased policy. In IAM, resource-based policies are attached to a resource (in this case, your Lambda function) and deﬁne who can access the resource and what actions they are allowed to take. For another AWS service to invoke your function through a trigger, your function's resource-based policy must grant that service permission to use the lambda:InvokeFunction action. If you create the trigger using",
  "grant that service permission to use the lambda:InvokeFunction action. If you create the trigger using the console, Lambda automatically adds this permission for you. To grant permission to other AWS users to access your function, you can deﬁne this in your function's resource-based policy in exactly the same way as for another AWS service or resource. You can also use an identity-based policy that's associated with the user. Best practices for Lambda permissions When you set permissions using IAM policies, security best practice is to grant only the permissions required to perform a task. This is known as the principle of least privilege. To get started granting permissions for your function, you might choose to use an AWS managed policy. Managed policies can be the quickest and easiest way to grant permissions to perform a task, but they might also include other permissions you don't need. As you move from early development through test and production, we recommend you reduce permissions to only those needed by deﬁning your own customer-managed policies. The same principle applies when granting permissions to access your function using a resourcebased policy. For example, if you want to give permission to Amazon S3 to invoke your function, Lambda permissions and roles 7 AWS Lambda Developer Guide best practice is to limit access to individual buckets, or buckets in particular AWS accounts, rather than giving blanket permissions to the S3 service. Lambda permissions and roles 8 AWS Lambda Developer Guide Running code with Lambda When you write a Lambda function, you are creating code that will run in a unique serverless environment. Understanding how Lambda actually runs your code involves two key aspects: the programming model that deﬁnes how your code interacts with Lambda, and the execution environment lifecycle that determines how Lambda manages your code's runtime",
  "with Lambda, and the execution environment lifecycle that determines how Lambda manages your code's runtime environment. The Lambda programming model Programming model functions as a common set of rules for how Lambda works with your code, regardless of whether you're writing in Python, Java, or any other supported language. The programming model includes your runtime and handler. 1. Lambda receives an event. 2. Lambda uses the runtime (like Python or Java) to prepare the event in a format your code can use. 3. The runtime sends the formatted event to your handler. 4. Your handler processes the event using the code you've written in your Lambda function. Essential to this model is the handler, where Lambda sends events to be processed by your code. Think of it as the entry point to your code. When Lambda receives an event, it passes this event and some context information to your handler. The handler then runs your code to process these events - for example, it might read a ﬁle when it's uploaded to Amazon S3, analyze an image, or update a database. Once your code ﬁnishes processing an event, the handler is ready to process the next one. The Lambda execution model While the programming model deﬁnes how Lambda interacts with your code, Execution environment is where Lambda actually runs your function — it's a secure, isolated compute space created speciﬁcally for your function. Each environment follows a lifecycle of three phases. 1. Initialization: Lambda creates the environment and gets everything ready to run your function. This includes setting up your chosen runtime, loading your code, and running any startup code you've written. 2. Invocation: When events arrive, Lambda uses this environment to run your function. The environment can process many events over time, one after another. As more events come",
  "The environment can process many events over time, one after another. As more events come in, Running code 9 AWS Lambda Developer Guide Lambda creates additional environments to handle the increased demand. When demand drops, Lambda stops environments that are no longer needed. 3. Shutdown: Eventually, Lambda will shut down environments. Before doing this, it gives your function a chance to clean up any remaining tasks. This environment handles important aspects of running your function. It provides your function with memory and a /tmp directory for temporary storage. It maintains resources like database connections between invocations, so your function can reuse them. It oﬀers features like provisioned concurrency, where Lambda prepares environments in advance to improve performance. Understanding the Lambda programming model Lambda provides a programming model that is common to all of the runtimes. The programming model deﬁnes the interface between your code and the Lambda system. You tell Lambda the entry point to your function by deﬁning a handler in the function conﬁguration. The runtime passes in objects to the handler that contain the invocation event and the context, such as the function name and request ID. When the handler ﬁnishes processing the ﬁrst event, the runtime sends it another. The function's class stays in memory, so clients and variables that are declared outside of the handler method in initialization code can be reused. To save processing time on subsequent events, create reusable resources like AWS SDK clients during initialization. Once initialized, each instance of your function can process thousands of requests. Your function also has access to local storage in the /tmp directory, a transient cache that can be used for multiple invocations. For more information, see Execution environment. When AWS X-Ray tracing is enabled, the runtime records separate subsegments for initialization and execution. The runtime captures",
  "tracing is enabled, the runtime records separate subsegments for initialization and execution. The runtime captures logging output from your function and sends it to Amazon CloudWatch Logs. In addition to logging your function's output, the runtime also logs entries when function invocation starts and ends. This includes a report log with the request ID, billed duration, initialization duration, and other details. If your function throws an error, the runtime returns that error to the invoker. Running code 10 AWS Lambda Developer Guide Note Logging is subject to CloudWatch Logs quotas. Log data can be lost due to throttling or, in some cases, when an instance of your function is stopped. Lambda scales your function by running additional instances of it as demand increases, and by stopping instances as demand decreases. This model leads to variations in application architecture, such as: • Unless noted otherwise, incoming requests might be processed out of order or concurrently. • Do not rely on instances of your function being long lived, instead store your application's state elsewhere. • Use local storage and class-level objects to increase performance, but keep to a minimum the size of your deployment package and the amount of data that you transfer onto the execution environment. For a hands-on introduction to the programming model in your preferred programming language, see the following chapters. • Building Lambda functions with Node.js • Building Lambda functions with Python • Building Lambda functions with Ruby • Building Lambda functions with Java • Building Lambda functions with Go • Building Lambda functions with C# • Building Lambda functions with PowerShell Understanding the Lambda execution environment lifecycle Lambda invokes your function in an execution environment, which provides a secure and isolated runtime environment. The execution environment manages the resources required to run your function. The execution environment",
  "environment. The execution environment manages the resources required to run your function. The execution environment also provides lifecycle support for the function's runtime and any external extensions associated with your function. Running code 11 AWS Lambda Developer Guide The function's runtime communicates with Lambda using the Runtime API. Extensions communicate with Lambda using the Extensions API. Extensions can also receive log messages and other telemetry from the function by using the Telemetry API. When you create your Lambda function, you specify conﬁguration information, such as the amount of memory available and the maximum execution time allowed for your function. Lambda uses this information to set up the execution environment. The function's runtime and each external extension are processes that run within the execution environment. Permissions, resources, credentials, and environment variables are shared between the function and the extensions. Topics • Lambda execution environment lifecycle • Cold starts and latency • Reducing cold starts with Provisioned Concurrency • Optimizing static initialization Lambda execution environment lifecycle Running code 12 AWS Lambda Developer Guide Each phase starts with an event that Lambda sends to the runtime and to all registered extensions. The runtime and each extension indicate completion by sending a Next API request. Lambda freezes the execution environment when the runtime and each extension have completed and there are no pending events. Topics • Init phase • Failures during the Init phase • Restore phase (Lambda SnapStart only) • Invoke phase • Failures during the invoke phase • Shutdown phase Init phase In the Init phase, Lambda performs three tasks: • Start all extensions (Extension init) • Bootstrap the runtime (Runtime init) • Run the function's static code (Function init) • Run any before-checkpoint runtime hooks (Lambda SnapStart only) The Init phase ends when the runtime and all extensions signal that they",
  "SnapStart only) The Init phase ends when the runtime and all extensions signal that they are ready by sending a Next API request. The Init phase is limited to 10 seconds. If all three tasks do not complete within 10 seconds, Lambda retries the Init phase at the time of the ﬁrst function invocation with the conﬁgured function timeout. When Lambda SnapStart is activated, the Init phase happens when you publish a function version. Lambda saves a snapshot of the memory and disk state of the initialized execution environment, persists the encrypted snapshot, and caches it for low-latency access. If you have a before-checkpoint runtime hook, then the code runs at the end of Init phase. Note The 10-second timeout doesn't apply to functions that are using provisioned concurrency or SnapStart. For provisioned concurrency and SnapStart functions, your initialization code Running code 13 AWS Lambda Developer Guide can run for up to 15 minutes. The time limit is 130 seconds or the conﬁgured function timeout (maximum 900 seconds), whichever is higher. When you use provisioned concurrency, Lambda initializes the execution environment when you conﬁgure the PC settings for a function. Lambda also ensures that initialized execution environments are always available in advance of invocations. You may see gaps between your function's invocation and initialization phases. Depending on your function's runtime and memory conﬁguration, you may also see variable latency on the ﬁrst invocation on an initialized execution environment. For functions using on-demand concurrency, Lambda may occasionally initialize execution environments ahead of invocation requests. When this happens, you may also observe a time gap between your function's initialization and invocation phases. We recommend you to not take a dependency on this behavior. Failures during the Init phase If a function crashes or times out during the Init phase, Lambda emits error",
  "phase If a function crashes or times out during the Init phase, Lambda emits error information in the INIT_REPORT log. Example — INIT_REPORT log for timeout INIT_REPORT Init Duration: 1236.04 ms Phase: init Status: timeout Example — INIT_REPORT log for extension failure INIT_REPORT Init Duration: 1236.04 ms Phase: init Status: error Error Type: Extension.Crash If the Init phase is successful, Lambda doesn't emit the INIT_REPORT log unless SnapStart or provisioned concurrency is enabled. SnapStart and provisioned concurrency functions always emit INIT_REPORT. For more information, see Monitoring for Lambda SnapStart. Restore phase (Lambda SnapStart only) When you ﬁrst invoke a SnapStart function and as the function scales up, Lambda resumes new execution environments from the persisted snapshot instead of initializing the function from scratch. If you have an after-restore runtime hook, the code runs at the end of the Restore phase. You are charged for the duration of after-restore runtime hooks. The runtime must load and afterRunning code 14 AWS Lambda Developer Guide restore runtime hooks must complete within the timeout limit (10 seconds). Otherwise, you'll get a SnapStartTimeoutException. When the Restore phase completes, Lambda invokes the function handler (the Invoke phase). Failures during the Restore phase If the Restore phase fails, Lambda emits error information in the RESTORE_REPORT log. Example — RESTORE_REPORT log for timeout RESTORE_REPORT Restore Duration: 1236.04 ms Status: timeout Example — RESTORE_REPORT log for runtime hook failure RESTORE_REPORT Restore Duration: 1236.04 ms Status: error Error Type: Runtime.ExitError For more information about the RESTORE_REPORT log, see Monitoring for Lambda SnapStart. Invoke phase When a Lambda function is invoked in response to a Next API request, Lambda sends an Invoke event to the runtime and to each extension. The function's timeout setting limits the duration of the entire Invoke phase. For example, if you set the function timeout as",
  "duration of the entire Invoke phase. For example, if you set the function timeout as 360 seconds, the function and all extensions need to complete within 360 seconds. Note that there is no independent post-invoke phase. The duration is the sum of all invocation time (runtime + extensions) and is not calculated until the function and all extensions have ﬁnished executing. The invoke phase ends after the runtime and all extensions signal that they are done by sending a Next API request. Failures during the invoke phase If the Lambda function crashes or times out during the Invoke phase, Lambda resets the execution environment. The following diagram illustrates Lambda execution environment behavior when there's an invoke failure: Running code 15 AWS Lambda Developer Guide In the previous diagram: • The ﬁrst phase is the INIT phase, which runs without errors. • The second phase is the INVOKE phase, which runs without errors. • At some point, suppose your function runs into an invoke failure (common causes include function timeouts, runtime errors, memory exhaustion, VPC connectivity issues, permission errors, concurrency limits, and various conﬁguration problems). For a complete list of possible invocation failures, see the section called “Invocation”. The third phase, labeled INVOKE WITH ERROR , illustrates this scenario. When this happens, the Lambda service performs a reset. The reset behaves like a Shutdown event. First, Lambda shuts down the runtime, then sends a Shutdown event to each registered external extension. The event includes the reason for the shutdown. If this environment is used for a new invocation, Lambda re-initializes the extension and runtime together with the next invocation. Note that the Lambda reset does not clear the /tmp directory content prior to the next init phase. This behavior is consistent with the regular shutdown phase. Note AWS is currently implementing",
  "phase. This behavior is consistent with the regular shutdown phase. Note AWS is currently implementing changes to the Lambda service. Due to these changes, you may see minor diﬀerences between the structure and content of system log messages and trace segments emitted by diﬀerent Lambda functions in your AWS account. If your function's system log conﬁguration is set to plain text, this change aﬀects the log messages captured in CloudWatch Logs when your function experiences an invoke failure. The following examples show log outputs in both old and new formats. These changes will be implemented during the coming weeks, and all functions in all AWS Regions except the China and GovCloud regions will transition to use the newformat log messages and trace segments. Example CloudWatch Logs log output (runtime or extension crash) - old style START RequestId: c3252230-c73d-49f6-8844-968c01d1e2e1 Version: $LATEST RequestId: c3252230-c73d-49f6-8844-968c01d1e2e1 Error: Runtime exited without providing a reason Runtime.ExitError Running code 16 AWS Lambda Developer Guide END RequestId: c3252230-c73d-49f6-8844-968c01d1e2e1 REPORT RequestId: c3252230-c73d-49f6-8844-968c01d1e2e1 Duration: 933.59 ms Billed Duration: 934 ms Memory Size: 128 MB Max Memory Used: 9 MB Example CloudWatch Logs log output (function timeout) - old style START RequestId: b70435cc-261c-4438-b9b6-efe4c8f04b21 Version: $LATEST 2024-03-04T17:22:38.033Z b70435cc-261c-4438-b9b6-efe4c8f04b21 Task timed out after 3.00 seconds END RequestId: b70435cc-261c-4438-b9b6-efe4c8f04b21 REPORT RequestId: b70435cc-261c-4438-b9b6-efe4c8f04b21 Duration: 3004.92 ms Billed Duration: 3000 ms Memory Size: 128 MB Max Memory Used: 33 MB Init Duration: 111.23 ms The new format for CloudWatch logs includes an additional statusﬁeld in the REPORT line. In the case of a runtime or extension crash, the REPORT line also includes a ﬁeld ErrorType. Example CloudWatch Logs log output (runtime or extension crash) - new style START RequestId: 5b866fb1-7154-4af6-8078-6ef6ca4c2ddd Version: $LATEST END RequestId: 5b866fb1-7154-4af6-8078-6ef6ca4c2ddd REPORT RequestId: 5b866fb1-7154-4af6-8078-6ef6ca4c2ddd Duration: 133.61 ms Billed Duration: 133 ms Memory Size: 128 MB Max Memory Used: 31 MB Init Duration:",
  "Billed Duration: 133 ms Memory Size: 128 MB Max Memory Used: 31 MB Init Duration: 80.00 ms Status: error Error Type: Runtime.ExitError Example CloudWatch Logs log output (function timeout) - new style START RequestId: 527cb862-4f5e-49a9-9ae4-a7edc90f0fda Version: $LATEST END RequestId: 527cb862-4f5e-49a9-9ae4-a7edc90f0fda REPORT RequestId: 527cb862-4f5e-49a9-9ae4-a7edc90f0fda Duration: 3016.78 ms Billed Duration: 3016 ms Memory Size: 128 MB Max Memory Used: 31 MB Init Duration: 84.00 ms Status: timeout • The fourth phase represents the INVOKE phase immediately following an invoke failure. Here, Lambda initializes the environment again by re-running the INIT phase. This is called a suppressed init. When suppressed inits occur, Lambda doesn't explicitly report an additional INIT phase in CloudWatch Logs. Instead, you may notice that the duration in the REPORT line includes an additional INIT duration + the INVOKE duration. For example, suppose you see the following logs in CloudWatch: Running code 17 AWS Lambda Developer Guide 2022-12-20T01:00:00.000-08:00 START RequestId: XXX Version: $LATEST 2022-12-20T01:00:02.500-08:00 END RequestId: XXX 2022-12-20T01:00:02.500-08:00 REPORT RequestId: XXX Duration: 3022.91 ms Billed Duration: 3000 ms Memory Size: 512 MB Max Memory Used: 157 MB In this example, the diﬀerence between the REPORT and START timestamps is 2.5 seconds. This doesn't match the reported duration of 3022.91 millseconds, because it doesn't take into account the extra INIT (suppressed init) that Lambda performed. In this example, you can infer that the actual INVOKE phase took 2.5 seconds. For more insight into this behavior, you can use the Accessing real-time telemetry data for extensions using the Telemetry API. The Telemetry API emits INIT_START, INIT_RUNTIME_DONE, and INIT_REPORT events with phase=invoke whenever suppressed inits occur in between invoke phases. • The ﬁfth phase represents the SHUTDOWN phase, which runs without errors. Shutdown phase When Lambda is about to shut down the runtime, it sends a Shutdown event to each registered external extension.",
  "to shut down the runtime, it sends a Shutdown event to each registered external extension. Extensions can use this time for ﬁnal cleanup tasks. The Shutdown event is a response to a Next API request. Duration limit: The maximum duration of the Shutdown phase depends on the conﬁguration of registered extensions: • 0 ms – A function with no registered extensions • 500 ms – A function with a registered internal extension • 2,000 ms – A function with one or more registered external extensions If the runtime or an extension does not respond to the Shutdown event within the limit, Lambda ends the process using a SIGKILL signal. After the function and all extensions have completed, Lambda maintains the execution environment for some time in anticipation of another function invocation. However, Lambda terminates execution environments every few hours to allow for runtime updates and maintenance —even for functions that are invoked continuously. You should not assume that the execution Running code 18 AWS Lambda Developer Guide environment will persist indeﬁnitely. For more information, see Implement statelessness in functions. When the function is invoked again, Lambda thaws the environment for reuse. Reusing the execution environment has the following implications: • Objects declared outside of the function's handler method remain initialized, providing additional optimization when the function is invoked again. For example, if your Lambda function establishes a database connection, instead of reestablishing the connection, the original connection is used in subsequent invocations. We recommend adding logic in your code to check if a connection exists before creating a new one. • Each execution environment provides between 512 MB and 10,240 MB, in 1-MB increments, of disk space in the /tmp directory. The directory content remains when the execution environment is frozen, providing a transient cache that can be used for",
  "when the execution environment is frozen, providing a transient cache that can be used for multiple invocations. You can add extra code to check if the cache has the data that you stored. For more information on deployment size limits, see Lambda quotas. • Background processes or callbacks that were initiated by your Lambda function and did not complete when the function ended resume if Lambda reuses the execution environment. Make sure that any background processes or callbacks in your code are complete before the code exits. Cold starts and latency When Lambda receives a request to run a function via the Lambda API, the service ﬁrst prepares an execution environment. During this initialization phase, the service downloads your code, starts the environment, and runs any initialization code outside of the main handler. Finally, Lambda runs the handler code. In this diagram, the ﬁrst two steps of downloading the code and setting up the environment are frequently referred to as a “cold start”. You are not charged for this time, but it does add latency to your overall invocation duration. Running code 19 AWS Lambda Developer Guide After the invocation completes, the execution environment is frozen. To improve resource management and performance, Lambda retains the execution environment for a period of time. During this time, if another request arrives for the same function, Lambda can reuse the environment. This second request typically ﬁnishes more quickly, since the execution environment is already fully set up. This is called a “warm start”. Cold starts typically occur in under 1% of invocations. The duration of a cold start varies from under 100 ms to over 1 second. In general, cold starts are typically more common in development and test functions than production workloads. This is because development and test functions are usually invoked",
  "test functions than production workloads. This is because development and test functions are usually invoked less frequently. Reducing cold starts with Provisioned Concurrency If you need predictable function start times for your workload, provisioned concurrency is the recommended solution to ensure the lowest possible latency. This feature pre-initializes execution environments, reducing cold starts. For example, a function with a provisioned concurrency of 6 has 6 execution environments prewarmed. Optimizing static initialization Static initialization happens before the handler code starts running in a function. This is the initialization code that you provide, that is outside of the main handler. This code is often used to import libraries and dependencies, set up conﬁgurations, and initialize connections to other services. Running code 20 AWS Lambda Developer Guide The following Python example shows importing, and conﬁguring modules, and creating the Amazon S3 client during the initialization phase, before the lambda_handler function runs during invoke. import os import json import cv2 import logging import boto3 s3 = boto3.client('s3') logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): # Handler logic... The largest contributor of latency before function execution comes from initialization code. This code runs when a new execution environment is created for the ﬁrst time. The initialization code is not run again if an invocation uses a warm execution environment. Factors that aﬀect initialization code latency include: • The size of the function package, in terms of imported libraries and dependencies, and Lambda layers. • The amount of code and initialization work. • The performance of libraries and other services in setting up connections and other resources. There are a number of steps that developers can take to optimize static initialization latency. If a function has many objects and connections, you may be able to rearchitect a single function into multiple, specialized functions. These are individually",
  "may be able to rearchitect a single function into multiple, specialized functions. These are individually smaller and each have less initialization code. It’s important that functions only import the libraries and dependencies that they need. For example, if you only use Amazon DynamoDB in the AWS SDK, you can require an individual service instead of the entire SDK. Compare the following three examples: // Instead of const AWS = require('aws-sdk'), use: const DynamoDB = require('aws-sdk/clients/dynamodb') Running code 21"
]